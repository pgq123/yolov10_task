{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-14T14:33:16.685987Z",
     "start_time": "2024-08-14T14:33:14.822906Z"
    }
   },
   "source": [
    "import os\n",
    "os.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = pow(2, 40).__str__()\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T09:18:06.374968Z",
     "start_time": "2024-08-14T09:17:59.104910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file1 = 'PWYL'\n",
    "file2 = 'CS'\n",
    "image = cv2.imread(f'{file1}/{file2}/{file1}-{file2}.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_RGBA2RGB)\n",
    "data = torch.from_numpy(image)\n",
    "\n",
    "(winW, winH) = (4096, 4096)\n",
    "stepSize = (2048, 2048)\n",
    "unfolded = data.unsqueeze(0).unfold(2, winW, stepSize[0]).unfold(3, winH, stepSize[1])\n",
    "windows = unfolded.contiguous().view(-1, 3, winW, winH).detach()\n",
    "# windows = windows.permute(0, 2, 1).view(num_windows, channels, winW, winH).numpy()\n",
    "out_dir = f'dataset/{file1}/{file2}'\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir, exist_ok=True)"
   ],
   "id": "d6173f6168ab050e",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "maximum size for tensor at dimension 3 is 3 but size is 4096",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m (winW, winH) \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m4096\u001B[39m, \u001B[38;5;241m4096\u001B[39m)\n\u001B[0;32m      7\u001B[0m stepSize \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m2048\u001B[39m, \u001B[38;5;241m2048\u001B[39m)\n\u001B[1;32m----> 8\u001B[0m unfolded \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munsqueeze\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munfold\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwinW\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstepSize\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munfold\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwinH\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstepSize\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m windows \u001B[38;5;241m=\u001B[39m unfolded\u001B[38;5;241m.\u001B[39mcontiguous()\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m3\u001B[39m, winW, winH)\u001B[38;5;241m.\u001B[39mdetach()\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# windows = windows.permute(0, 2, 1).view(num_windows, channels, winW, winH).numpy()\u001B[39;00m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: maximum size for tensor at dimension 3 is 3 but size is 4096"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    " # windows = windows.numpy()\n",
    "s = time.perf_counter()\n",
    "window = windows[0, :, :, :].detach()\n",
    "to_pil = transforms.ToPILImage()\n",
    "window = to_pil(window)\n",
    "window.save(f'test.jpg')\n",
    "e = time.perf_counter()\n",
    "print(f'time2: {e - s}')\n",
    "# torch.save(window, f'{out_dir}/{file1}_{file2}_{0}.pt')"
   ],
   "id": "ca025bc30cee7080",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T12:51:55.599194Z",
     "start_time": "2024-08-14T12:51:55.585194Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def some_func(roi):\n",
    "    '''\n",
    "    simple function to return the mean of the region\n",
    "    of interest\n",
    "    '''\n",
    "    return np.mean(roi)"
   ],
   "id": "d8a2e9d418f46f39",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T12:54:10.063946Z",
     "start_time": "2024-08-14T12:54:10.050854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img = np.zeros((37262,32763), dtype=np.uint8)\n",
    "img.strides"
   ],
   "id": "1603ec82fe6ac2e0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32763, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T13:10:14.055084Z",
     "start_time": "2024-08-14T13:10:14.045084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def window_signal(signal, window, overlap):\n",
    "    \"\"\" \n",
    "    Windowing function for data segmentation.\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    signal: ndarray\n",
    "            The signal to segment.\n",
    "    window: int\n",
    "            Window length, in samples.\n",
    "    overlap: int\n",
    "             Number of samples to overlap\n",
    "\n",
    "    Returns: \n",
    "    --------\n",
    "    nd-array \n",
    "            A copy of the signal array with shape (rows, window),\n",
    "            where row = (N-window)//(window-overlap) + 1\n",
    "    \"\"\"\n",
    "    N = signal.reshape(-1).shape[0]\n",
    "    if (window == overlap):\n",
    "        rows = N//window\n",
    "        overlap = 0\n",
    "    else:\n",
    "        rows = (N-window)//(window-overlap) + 1\n",
    "        miss = (N-window)%(window-overlap)\n",
    "        if(miss != 0):\n",
    "            print('Windowing led to the loss of ', miss, ' samples.')\n",
    "    item_size = signal.dtype.itemsize \n",
    "    strides = (window - overlap) * item_size\n",
    "    return np.lib.stride_tricks.as_strided(signal, shape=(rows, window),\n",
    "                                           strides=(strides, item_size))"
   ],
   "id": "c09fdd6bcb09d13a",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T14:08:07.396674Z",
     "start_time": "2024-08-14T14:08:07.386674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def Unfold(max_x, max_y, winH, winW, stepSize):\n",
    "    x_points_l = np.array([i for i in range(0, max_x, stepSize[0]) if i + winH <= max_x])\n",
    "    y_points_u = np.array([i for i in range(0, max_y, stepSize[1]) if i + winW <= max_y])\n",
    "\n",
    "    x_wins_cnt = len(x_points_l)\n",
    "    y_wins_cnt = len(y_points_u)\n",
    "    wins_cnt = x_wins_cnt * y_wins_cnt\n",
    "\n",
    "    w_lu = np.repeat([x_points_l], y_wins_cnt, axis=0)\n",
    "    w_lu = np.repeat(w_lu, 2, axis=1)\n",
    "    w_lu[:, 1::2] = np.repeat(y_points_u[:, np.newaxis], x_wins_cnt, axis=1)\n",
    "    w_lu = w_lu.reshape(wins_cnt, 2)\n",
    "\n",
    "    w_ru = np.copy(w_lu)\n",
    "    w_ru[:, 0] += winW\n",
    "\n",
    "    w_rd = np.copy(w_ru)\n",
    "    w_rd[:, 1] += winH\n",
    "\n",
    "    w_ld = np.copy(w_rd)\n",
    "    w_ld[:, 0] -= winW\n",
    "\n",
    "    windows = np.hstack((w_lu, w_ru, w_rd, w_ld))\n",
    "    return windows\n"
   ],
   "id": "e478093de66e4a9f",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T14:33:30.972238Z",
     "start_time": "2024-08-14T14:33:22.150431Z"
    }
   },
   "cell_type": "code",
   "source": "img = cv2.imread('PWYL/CS/PWYL-CS.jpg')",
   "id": "2ae0d0aa724d5fc9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T14:33:33.480244Z",
     "start_time": "2024-08-14T14:33:33.474698Z"
    }
   },
   "cell_type": "code",
   "source": "print(img.strides)",
   "id": "69e184c8fafb0da0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111786, 3, 1)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T14:08:14.854243Z",
     "start_time": "2024-08-14T14:08:14.844243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_x, max_y = img.shape[1], img.shape[0]\n",
    "winH, winW = 4096, 4096\n",
    "stepSize = (2048, 2048)"
   ],
   "id": "403d5e3ad7e9426d",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T14:09:26.677704Z",
     "start_time": "2024-08-14T14:09:26.663248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "windows = Unfold(max_x, max_y, winH, winW, stepSize)\n",
    "windows3 = np.zeros((238, 4096, 4096, 3))\n",
    "for i in range(windows.shape[0]):\n",
    "    windows3[i, :, :, :] = img[windows[i, 1]:windows[i, 5], windows[i, 0]:windows[i, 2]]"
   ],
   "id": "c7d71666b35ddeaf",
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 89.2 GiB for an array with shape (238, 4096, 4096, 3) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m windows \u001B[38;5;241m=\u001B[39m Unfold(max_x, max_y, winH, winW, stepSize)\n\u001B[1;32m----> 2\u001B[0m windows3 \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mzeros\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m238\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m4096\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m4096\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(windows\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]):\n\u001B[0;32m      4\u001B[0m     windows3[i, :, :, :] \u001B[38;5;241m=\u001B[39m img[windows[i, \u001B[38;5;241m1\u001B[39m]:windows[i, \u001B[38;5;241m5\u001B[39m], windows[i, \u001B[38;5;241m0\u001B[39m]:windows[i, \u001B[38;5;241m2\u001B[39m]]\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 89.2 GiB for an array with shape (238, 4096, 4096, 3) and data type float64"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T13:17:40.258835Z",
     "start_time": "2024-08-14T13:17:40.252834Z"
    }
   },
   "cell_type": "code",
   "source": "windows1 = window_signal(img, 4096*4096, 2048*4096)",
   "id": "45057afea17da3bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32763, 37262, 3)\n",
      "Windowing led to the loss of  5011630  samples.\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T14:10:00.737993Z",
     "start_time": "2024-08-14T14:09:57.575801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 获取图片形状\n",
    "height, width, channels = img.shape\n",
    "\n",
    "# 定义窗口大小和步幅\n",
    "winH, winW = 4096, 4096\n",
    "stepH, stepW = 2048, 2048\n",
    "\n",
    "# 计算步幅\n",
    "strides = (stepH * img.strides[0], stepW*img.strides[1], img.strides[0], img.strides[1], img.strides[2])\n",
    "\n",
    "# 计算输出形状\n",
    "out_shape = ((height - winH) // stepH + 1, (width - winW) // stepW + 1, winH, winW, channels)\n",
    "\n",
    "# 使用 np.lib.stride_tricks.as_strided 生成滑动窗口\n",
    "windows2 = np.lib.stride_tricks.as_strided(img, shape=out_shape, strides=strides)\n",
    "\n",
    "windows2 = windows2.reshape(-1, winH, winW, channels)\n",
    "print(windows2.shape)"
   ],
   "id": "b125f75e05845207",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(238, 4096, 4096, 3)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T13:50:27.464547Z",
     "start_time": "2024-08-14T13:50:27.450056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(windows.shape)\n",
    "print(windows2.shape)\n",
    "print(windows2)"
   ],
   "id": "a5f5fe41d9da29c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(238, 8)\n",
      "(33168, 4096)\n",
      "[[50 67 66 ...  1  0  0]\n",
      " [67 66 48 ...  0  0  1]\n",
      " [66 48 67 ...  0  1  0]\n",
      " ...\n",
      " [ 4  0  0 ...  1  0  0]\n",
      " [ 0  0  4 ...  0  0  1]\n",
      " [ 0  4  0 ...  0  1  0]]\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9eab3b4905c11c06"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
